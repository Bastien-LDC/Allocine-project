{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Movies Data From AlloCiné.fr\n",
    "\n",
    "This script builds a DataFrame by web scraping the data from AlloCiné — a company which provides information on French cinema. Because of the long delay, we choose to scrape the data in two steps : \n",
    "- First we scrape the url of each movie with `getMoviesUrl()`\n",
    "- Lastly we use the url list to scrape the data for each movie with `ScrapeURL()`\n",
    "\n",
    "*Note : We use the popular BeautifulSoup package*\n",
    "\n",
    "## Functions :\n",
    "\n",
    "### `getMoviesUrl(start_page, end_page)` :\n",
    "\n",
    "Save a CSV files of the url list as `movie_url.csv`. The argument must be integers and are used to select the range of page you want to scrape the data from. The `end_page` is included.\n",
    "\n",
    "### `ScrapeURL(movie_url)` :\n",
    "\n",
    "Iterate over the list of url generated by `getMoviesUrl()` and scrape the data for each movie. In the process, we extract :\n",
    "\n",
    "- `id` : Allocine movie id\n",
    "- `title` : the movie's title (in french)\n",
    "- `release_date`: the original release date\n",
    "- `duration`: the movies length\n",
    "- `genres` : the movies types (as an array, up to three different types)\n",
    "- `directors` : movies directors (as an array)\n",
    "- `actors` : main characters of the movies (as an array)\n",
    "- `nationality`: nationality of the movies (as an array)\n",
    "- `press_rating`: press ratings (from 0.5 to 5 stars)\n",
    "- `nb_press_rating`: number of press votes\n",
    "- `spec_rating`:  AlloCiné users ratings (from 0.5 to 5 stars)\n",
    "- `nb_spec_rating`: number of users votes\n",
    "- `summary`: short summary of the movie in french\n",
    "- `poster`: url of the movie's poster\n",
    "\n",
    "The function `ScrapeURL()` returns two objects : the data as a dataframe and the url list of error as a list. In addition the two objects are saved as `allocine_movies.csv` and `allocine_errors.csv`. You could pass the list of errors into `ScrapeURL()` to get the extra data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basti\\AppData\\Local\\Temp\\ipykernel_29064\\66211388.py:16: DeprecationWarning: Importing clear_output from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import clear_output\n"
     ]
    }
   ],
   "source": [
    "# Import libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from time import time\n",
    "from time import sleep\n",
    "from datetime import timedelta, datetime\n",
    "from urllib.request import urlopen\n",
    "from random import randint\n",
    "from bs4 import BeautifulSoup\n",
    "import dateparser\n",
    "import os\n",
    "\n",
    "from warnings import warn\n",
    "from IPython.core.display import clear_output\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions: Getting movie infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A SUPPRIMER APRES TESTS\n",
    "response = urlopen(\"http://www.allocine.fr/film/fichefilm_gen_cfilm=211012.html\")\n",
    "html_text = response.read().decode(\"utf-8\")\n",
    "movie_html_soup = BeautifulSoup(html_text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie ID: `get_movie_ID(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_ID(movie_soup):\n",
    "    '''\n",
    "    Scrape the movie ID from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie ID.'''\n",
    "    movie_ID = re.sub(\n",
    "        r\"\\D\", \"\", movie_soup.find(\"nav\", {\"class\": \"third-nav\"}).a[\"href\"]\n",
    "        )\n",
    "    return movie_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie title: `get_movie_title(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the movie title\n",
    "def get_movie_title(movie_soup):\n",
    "    '''\n",
    "    Scrape the movie title from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie title.'''\n",
    "    movie_title = movie_soup.find(\"div\", {\"class\": \"titlebar-title\"}).text.strip()\n",
    "    return movie_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie release date: `get_movie_release_date(movie_soup)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert French months to English months: `convert_month(month)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert french months to english months\n",
    "def convert_month(month):\n",
    "    if month == \"janvier\":\n",
    "        return \"January\"\n",
    "    elif month == \"février\":\n",
    "        return \"February\"\n",
    "    elif month == \"mars\":\n",
    "        return \"March\"\n",
    "    elif month == \"avril\":\n",
    "        return \"April\"\n",
    "    elif month == \"mai\":\n",
    "        return \"May\"\n",
    "    elif month == \"juin\":\n",
    "        return \"June\"\n",
    "    elif month == \"juillet\":\n",
    "        return \"July\"\n",
    "    elif month == \"août\":\n",
    "        return \"August\"\n",
    "    elif month == \"septembre\":\n",
    "        return \"September\"\n",
    "    elif month == \"octobre\":\n",
    "        return \"October\"\n",
    "    elif month == \"novembre\":\n",
    "        return \"November\"\n",
    "    elif month == \"décembre\":\n",
    "        return \"December\"\n",
    "    else:\n",
    "        return \"Unknown\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main function: `get_movie_release_date(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the movie release date\n",
    "def get_movie_release_date(movie_soup):\n",
    "    # Get the movie release date\n",
    "    movie_release_date = movie_soup.find(\"span\", {\"class\": \"date\"})\n",
    "    if movie_release_date:\n",
    "        movie_release_date = movie_release_date.text.strip()\n",
    "        month = movie_release_date.split(' ')[1]\n",
    "        movie_release_date = movie_release_date.replace(month, convert_month(month))\n",
    "        movie_release_date = dateparser.parse(movie_release_date, date_formats=[\"%d %B %Y\"]).date()        \n",
    "    return movie_release_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2022, 3, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd = get_movie_release_date(movie_html_soup)\n",
    "rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd >= datetime.now().date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie duration: `get_movie_duration(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_duration(movie_soup):\n",
    "    '''\n",
    "    Scrape the movie duration from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie duration in minutes.'''\n",
    "    movie_duration = movie_soup.find(\"span\", {\"class\": \"spacer\"}).next_sibling.strip()\n",
    "    if movie_duration != \"\":\n",
    "        duration_timedelta = pd.to_timedelta(movie_duration).components\n",
    "        movie_duration = duration_timedelta.hours * 60 + duration_timedelta.minutes\n",
    "    return movie_duration    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie genres: `get_movie_genres(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_genres(movie_soup):\n",
    "    ''' \n",
    "    Scrape the movie genres from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie genres. None if no genres are found.'''\n",
    "    div_genres = movie_soup.find(\"div\", {\"class\": \"meta-body-item meta-body-info\"})\n",
    "    if div_genres:\n",
    "        movie_genres = [\n",
    "            genre.text\n",
    "            for genre in div_genres.find_all(\"span\", class_=re.compile(r\".*==$\"))\n",
    "            if \"\\n\" not in genre.text\n",
    "        ]\n",
    "        return \", \".join(movie_genres)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie directors: `get_movie_directors(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_directors(movie_soup):\n",
    "    '''\n",
    "    Scrape the movie directors from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie directors. None if no directors are found.'''\n",
    "    div_directors = movie_soup.find_all(\n",
    "            \"div\", {\"class\": \"meta-body-item meta-body-direction\"}\n",
    "        )\n",
    "    if div_directors:\n",
    "        movie_directors = [\n",
    "            link.text\n",
    "            for directors in div_directors\n",
    "            for link in directors.find_all(\n",
    "                [\"a\", \"span\"], class_=re.compile(r\".*blue-link$\")\n",
    "            )\n",
    "        ]\n",
    "        return \", \".join(set(movie_directors))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie actors: `get_movie_actors(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_actors(movie_soup):\n",
    "    '''\n",
    "    Scrape the movie actors from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie actors. None if no actors are found.'''\n",
    "    div_actors = movie_soup.find(\"div\", {\"class\": \"meta-body-item meta-body-actor\"})\n",
    "    if div_actors:\n",
    "        movie_actors = [actor.text for actor in div_actors.find_all([\"a\", \"span\"])][1:]\n",
    "        return \", \".join(movie_actors)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie nationality: `get_movie_nationality(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the movie nationality\n",
    "def get_movie_nationality(movie_soup):\n",
    "    '''\n",
    "    Scrape the movie nationality from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie nationality.'''\n",
    "    movie_nationality = [\n",
    "            nationality.text.strip()\n",
    "            for nationality in movie_soup.find_all(\"span\", class_=\"nationality\")\n",
    "        ]\n",
    "    return \", \".join(movie_nationality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie press ratings: `get_movie_press_rating(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the movie press ratings\n",
    "def get_movie_press_rating(movie_soup):\n",
    "    '''\n",
    "    Scrape the movie average press rating from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie average press rating. None if no rating is found.'''\n",
    "    # get all the available ratings\n",
    "    movie_ratings = movie_soup.find_all(\"div\", class_=\"rating-item\")\n",
    "    for ratings in movie_ratings:\n",
    "        if \"Presse\" in ratings.text:\n",
    "            return float(\n",
    "                re.sub(\n",
    "                    \",\", \".\", ratings.find(\"span\", {\"class\": \"stareval-note\"}).text\n",
    "                )\n",
    "            )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie number of press ratings: `get_movie_press_rating_count(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the movie number of press rating\n",
    "def get_movie_press_rating_count(movie_soup):\n",
    "    '''\n",
    "    Scrape the movie number of press ratings from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie number of press ratings. None if no rating is found.'''\n",
    "    # get all the available ratings\n",
    "    movie_ratings = movie_soup.find_all(\"div\", class_=\"rating-item\")\n",
    "    for ratings in movie_ratings:\n",
    "        if \"Presse\" in ratings.text:\n",
    "            return float(\n",
    "                re.match(\n",
    "                    r\"\\s\\d+\",\n",
    "                    ratings.find(\"span\", {\"class\": \"stareval-review\"}).text,\n",
    "                ).group()\n",
    "            )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie spectator ratings: `get_movie_spec_rating(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the movie spec ratings\n",
    "def get_movie_spec_rating(movie_soup):\n",
    "    '''\n",
    "    Scrape the movie average spec rating from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie average spec rating. None if no rating is found.'''\n",
    "    # get all the available ratings\n",
    "    movie_ratings = movie_soup.find_all(\"div\", class_=\"rating-item\")\n",
    "    for ratings in movie_ratings:\n",
    "        if \"Spectateurs\" in ratings.text:\n",
    "            return float(\n",
    "                re.sub(\n",
    "                    \",\", \".\", ratings.find(\"span\", {\"class\": \"stareval-note\"}).text\n",
    "                )\n",
    "            )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie number of spec ratings: `get_movie_spec_rating_count(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the number of spec ratings\n",
    "def get_movie_spec_rating_count(movie_soup):\n",
    "    '''\n",
    "    Scrape the movie number of spec ratings from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie number of spec ratings. None if no rating is found.'''\n",
    "    # get all the available ratings\n",
    "    movie_ratings = movie_soup.find_all(\"div\", class_=\"rating-item\")\n",
    "    for ratings in movie_ratings:\n",
    "        if \"Spectateurs\" in ratings.text:\n",
    "            return float(\n",
    "                re.match(\n",
    "                    r\"\\s\\d+\",\n",
    "                    ratings.find(\"span\", {\"class\": \"stareval-review\"}).text\n",
    "                ).group()  \n",
    "            )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie summary: `get_movie_summary(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the movie summary\n",
    "def get_movie_summary(movie_soup):\n",
    "    '''\n",
    "    Scrape the movie summary from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie summary. None if no summary is found.'''\n",
    "    movie_summary = movie_soup.find(\n",
    "            \"section\", {\"class\": \"section ovw ovw-synopsis\"}\n",
    "        ).find(\"div\", {\"class\": \"content-txt\"})\n",
    "    if movie_summary:\n",
    "        movie_summary = movie_summary.text.strip()\n",
    "        return unicodedata.normalize(\"NFKC\", movie_summary)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie poster: `get_movie_poster(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_poster(movie_soup):\n",
    "    '''\n",
    "    Scrape the movie poster link from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie poster link.'''\n",
    "    # Get the movie poster\n",
    "    return movie_soup.find(\"img\", {\"class\": \"thumbnail-img\"})[\"src\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download movie poster: `download_movie_poster(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_movie_poster(poster_link, movie_name):\n",
    "    '''\n",
    "    Download the movie poster from the poster link.\n",
    "    :param poster_link: The poster link.\n",
    "    :param movie_name: The movie name.\n",
    "    :return: nothing but saves the movie poster as a jpg file.'''\n",
    "    # Download the movie poster\n",
    "    poster = urlopen(poster_link)\n",
    "    poster_path = \"../Movies/Posters/\"\n",
    "    os.makedirs(os.path.dirname(poster_path), exist_ok=True) #create folders if not exists\n",
    "    save_path = f\"{poster_path}{movie_name.replace(' ','_').replace('_:_','_').replace(':_','_').replace(',','')}_poster.jpg\"\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        f.write(poster.read())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `getMoviesUrl(start_page, end_page)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMoviesUrl(start_page, end_page=None, nb_pages=1):\n",
    "    '''\n",
    "    Scrape the movies urls from the AlloCine website's movie page (http://www.allocine.fr/films/).\n",
    "    It will ignore the movies that has not been released yet.\n",
    "    :param start_page: The first page to scrape.\n",
    "    :param end_page: The last page to scrape (included) (optional).\n",
    "    :param nb_pages: The number of pages to scrape (default 1).\n",
    "    :return: Nothing but saves the list of movies urls in a csv file.'''\n",
    "    if start_page <= 0:\n",
    "        raise ValueError('start_page must be positive !')\n",
    "\n",
    "    # Set the list\n",
    "    movie_url = []\n",
    "\n",
    "    # Preparing the setting and monitoring of the loop\n",
    "    start_time = time()\n",
    "    p_requests = start_page\n",
    "    if nb_pages < 1:\n",
    "        nb_pages = 1\n",
    "    if end_page == None or end_page < start_page:\n",
    "        end_page = start_page + nb_pages - 1\n",
    "    \n",
    "    m_requests = 0\n",
    "        \n",
    "    for p in range(start_page, end_page + 1):\n",
    "\n",
    "        # Get request\n",
    "        url = f'http://www.allocine.fr/films/?page={p}'\n",
    "        response = urlopen(url)\n",
    "        \n",
    "        # Pause the loop\n",
    "        sleep(randint(1,2))\n",
    "            \n",
    "        # Monitoring the requests\n",
    "        elapsed_time = time() - start_time\n",
    "        print(f'>Page Request: {p_requests}; Frequency: {p_requests/elapsed_time} requests/s')\n",
    "        clear_output(wait = True)\n",
    "            \n",
    "        # Warning for non-200 status codes\n",
    "        if response.status != 200:\n",
    "            warn(f'>Page Request: {p_requests}; Status code: {response.status_code}')\n",
    "\n",
    "        # Break the loop if the number of requests is greater than expected\n",
    "        if p_requests > end_page:\n",
    "            warn('Number of requests was greater than expected.')\n",
    "            break\n",
    "\n",
    "        # Parse the content of the request with BeautifulSoup\n",
    "        html_text = response.read().decode(\"utf-8\")\n",
    "        html_soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "        # Select all the movies url from a single page\n",
    "        movies = html_soup.find_all('h2', 'meta-title')\n",
    "        m_requests += len(movies)\n",
    "        # Count the number of movies not yet released \n",
    "        nr_movies = 0\n",
    "       \n",
    "        # Monitoring the requests\n",
    "        print(f'>Page Request: {p_requests}; Movie Request: {m_requests}')\n",
    "        clear_output(wait = True)\n",
    "        \n",
    "        # Pause the loop\n",
    "        sleep(1)\n",
    "        \n",
    "        for movie in movies:\n",
    "            m_url = f'http://www.allocine.fr{movie.a[\"href\"]}'\n",
    "            m_rd = get_movie_release_date(m_url)\n",
    "            # We keep the movie url if the movie has already been released\n",
    "            if m_rd <= datetime.now().date():\n",
    "                movie_url.append(m_url) \n",
    "            else:\n",
    "                nr_movies += 1\n",
    "        p_requests += 1\n",
    "\n",
    "    # Saving the files\n",
    "    movie_path = '../Movies/Data/'\n",
    "    os.makedirs(os.path.dirname(movie_path), exist_ok=True) #create folders if not exists\n",
    "    print(f'--> Done; {p_requests-1} Page Requests and {m_requests-nr_movies}/{m_requests} Movie Requests in {timedelta(seconds=time()-start_time)}')\n",
    "    r = np.asarray(movie_url)\n",
    "    np.savetxt(f\"{movie_path}movie_url.csv\", r, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `ScrapeURL(movie_url)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ScrapeURL(movie_url: list, dwld_poster: bool = False):\n",
    "    '''\n",
    "    Scrape the data from the movies urls.\n",
    "    :param movie_url: The list of movies urls.\n",
    "    :param dwld_poster: Boolean to download the movie poster (default False).\n",
    "    :return: The dataframe of the movies and the dataframe of the urls that return an error. Both are saved in a csv file.'''\n",
    "    # init the dataframe\n",
    "    c = [\"id\",\n",
    "        \"title\",\n",
    "        \"release_date\",\n",
    "        \"duration\",\n",
    "        \"genres\",\n",
    "        \"directors\",\n",
    "        \"actors\",\n",
    "        \"nationality\",\n",
    "        \"press_rating\",\n",
    "        \"nb_press_rating\",\n",
    "        \"spect_rating\",\n",
    "        \"nb_spect_rating\",\n",
    "        \"summary\",\n",
    "        \"poster_link\"\n",
    "    ]\n",
    "    df = pd.DataFrame(columns=c)\n",
    "    \n",
    "    # preparing the setting and monitoring loop\n",
    "    start_time = time()\n",
    "    n_request = 0\n",
    "    \n",
    "    # init list to save errors\n",
    "    errors = []\n",
    "    \n",
    "    # request loop\n",
    "    for url in movie_url:\n",
    "        try :\n",
    "            response = urlopen(url)\n",
    "\n",
    "            # Pause the loop\n",
    "            sleep(randint(1,2))\n",
    "\n",
    "            # Monitoring the requests\n",
    "            n_request += 1\n",
    "            \n",
    "            elapsed_time = time() - start_time\n",
    "            print(f'Request #{n_request}; Frequency: {n_request/elapsed_time} requests/s')\n",
    "            clear_output(wait = True)\n",
    "\n",
    "            # Pause the loop\n",
    "            sleep(randint(1,2))\n",
    "\n",
    "            # Warning for non-200 status codes\n",
    "            if response.status != 200:\n",
    "                warn('Request #{}; Status code: {}'.format(n_request, response.status_code))\n",
    "                errors.append(url)\n",
    "\n",
    "            # Parse the content of the request with BeautifulSoup\n",
    "            html_text = response.read().decode(\"utf-8\")\n",
    "            movie_html_soup = BeautifulSoup(html_text, 'html.parser')\n",
    "            \n",
    "            if movie_html_soup.find('div', 'titlebar-title'):\n",
    "                # Scrape the movie ID \n",
    "                tp_id = get_movie_ID(movie_html_soup)\n",
    "                # Scrape the title\n",
    "                tp_title = get_movie_title(movie_html_soup)\n",
    "                # Scrape the release date\n",
    "                tp_release_dt = get_movie_release_date(movie_html_soup)\n",
    "                # Scrape the duration\n",
    "                tp_duration = get_movie_duration(movie_html_soup)\n",
    "                # Scrape the directors\n",
    "                tp_director = get_movie_directors(movie_html_soup)\n",
    "                # Scrape the actors\n",
    "                tp_actor = get_movie_actors(movie_html_soup)\n",
    "                # Scrape the genres\n",
    "                tp_genre = get_movie_genres(movie_html_soup)\n",
    "                # Scrape the nationality\n",
    "                tp_nation = get_movie_nationality(movie_html_soup)\n",
    "                # Scrape the press ratings\n",
    "                tp_press_rating = get_movie_press_rating(movie_html_soup)\n",
    "                # Scrape the number of press ratings\n",
    "                tp_nb_press_rating = get_movie_press_rating_count(movie_html_soup)\n",
    "                # Scrape the spec ratings\n",
    "                tp_spec_rating = get_movie_spec_rating(movie_html_soup)\n",
    "                # Scrape the number of spec ratings\n",
    "                tp_nb_spec_rating = get_movie_spec_rating_count(movie_html_soup)\n",
    "                # Scrape the summary\n",
    "                tp_summary = get_movie_summary(movie_html_soup)\n",
    "                # Scrape the poster\n",
    "                tp_poster = get_movie_poster(movie_html_soup)\n",
    "                # Download the poster (optional)\n",
    "                if dwld_poster:\n",
    "                    download_movie_poster(tp_poster, tp_title)\n",
    "                \n",
    "                # Append the data\n",
    "                df_tmp = pd.DataFrame({'id': [tp_id],\n",
    "                                       'title': [tp_title],\n",
    "                                       'release_date': [tp_release_dt],\n",
    "                                       'duration': [tp_duration],\n",
    "                                       'genres': [tp_genre],\n",
    "                                       'directors': [tp_director],\n",
    "                                       'actors': [tp_actor],\n",
    "                                       'nationality': [tp_nation],\n",
    "                                       'press_rating': [tp_press_rating],\n",
    "                                       'nb_press_rating': [tp_nb_press_rating],\n",
    "                                       'spect_rating': [tp_spec_rating],\n",
    "                                       'nb_spect_rating': [tp_nb_spec_rating],\n",
    "                                       'summary': [tp_summary],\n",
    "                                       'poster_link': [tp_poster]})\n",
    "                \n",
    "                df = pd.concat([df, df_tmp], ignore_index=True)\n",
    "                \n",
    "        except:\n",
    "            errors.append(url)\n",
    "            warn(f'Request #{n_request} fail; Total errors : {len(errors)}')\n",
    "            traceback.print_exc()\n",
    "            \n",
    "    # monitoring \n",
    "    movie_path = '../Movies/Data/'\n",
    "    os.makedirs(os.path.dirname(movie_path), exist_ok=True) #create folders if not exists\n",
    "    elapsed_time = time() - start_time\n",
    "    print(f'Done; {n_request} requests in {timedelta(seconds=elapsed_time)} with {len(errors)} errors')\n",
    "    clear_output(wait = True)\n",
    "    df.to_csv(f\"{movie_path}allocine_movies.csv\", index=False)\n",
    "    # list to dataframe\n",
    "    errors_df = pd.DataFrame(errors, columns=['url'])\n",
    "    errors_df.to_csv(f\"{movie_path}allocine_errors.csv\")\n",
    "    # return dataframe and errors\n",
    "    return df, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting movies urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Done; 20 Page Requests and 300 Movie Requests in 0:00:58.376464\n"
     ]
    }
   ],
   "source": [
    "# Scrape the page from start_page to end_page (included) or with nb_pages\n",
    "start_page = 1\n",
    "end_page = None\n",
    "nb_pages = 20\n",
    "getMoviesUrl(start_page, end_page=end_page, nb_pages=nb_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the list of urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the list of urls \n",
    "m_url = pd.read_csv(\"../Movies/Data/movie_url.csv\",names=['url'])\n",
    "m_url = m_url['url'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done; 300 requests in 0:17:16.264138 with 2 errors\n"
     ]
    }
   ],
   "source": [
    "# Scrape the data \n",
    "d, e = ScrapeURL(m_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
