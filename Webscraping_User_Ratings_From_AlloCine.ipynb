{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping User Ratings From AlloCiné.fr\n",
    "\n",
    "This script builds a DataFrame by web scraping the data from AlloCiné — this time, its purpose is to retrieve the user ratings of movies and series from the website of AlloCiné. We will proceed as follows: \n",
    "- We use the series and movies url lists generated in the other scripts to get the comments section urls with `getCommentsUrl()`.\n",
    "- From there, we scrape the user ID and their rating for each movie with `ScrapeURL()`.\n",
    "- The user can be either a person or a press newspaper. Separated files are generated for each type of user.\n",
    "\n",
    "*Note : We use the popular BeautifulSoup package*\n",
    "\n",
    "## Functions :\n",
    "\n",
    "### `getCommentsUrl()`\n",
    "\n",
    "Iterate over the list of movies or series url generated by `getMoviesUrl()` in the previous scripts and get the comments section url. \n",
    "We then store it in a csv file entitled `movie_comments_url.csv` (resp. `series_comments_url.csv`).\n",
    "\n",
    "### `ScrapeURL(urls)` :\n",
    "\n",
    "Iterate over the list of movies or series comments section url generated by `getCommentsUrl()` and scrape the data for each movie or series ratings. In the process, we extract :\n",
    "\n",
    "- `user_id` : Allocine user id (person or press)\n",
    "- `id` : Allocine movie or series id\n",
    "- `user_rating`: AlloCiné users ratings (from 0.5 to 5 stars) \n",
    "\n",
    "\n",
    "The function `ScrapeURL()` returns two objects : the user_rating and press-rating as two dataframes. In addition, the two objects are saved as `user_ratings_movies.csv` and `press_ratings_movies.csv` (respectively `user_ratings_series.csv` and `press_ratings_series.csv`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basti\\AppData\\Local\\Temp\\ipykernel_7036\\678141690.py:15: DeprecationWarning: Importing clear_output from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import clear_output\n"
     ]
    }
   ],
   "source": [
    "# Import libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from time import time\n",
    "from time import sleep\n",
    "from datetime import timedelta\n",
    "from urllib.request import urlopen\n",
    "from random import randint\n",
    "from bs4 import BeautifulSoup\n",
    "import dateparser\n",
    "\n",
    "from warnings import warn\n",
    "from IPython.core.display import clear_output\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `getCommentsUrl(urls)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: `getMoviesCommentsUrl(urls)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the comments section url for each movie\n",
    "# You can select the spectateurs or presse section, or both\n",
    "def getMoviesCommentsUrl(movies_df: pd.DataFrame, spect=False, press=False):\n",
    "    \n",
    "    # Get the list of movies_id from the movies_df\n",
    "    movies_id_list = movies_df['id'].tolist()\n",
    "\n",
    "    # Set the list\n",
    "    press_url_list = []\n",
    "    user_url_list = []\n",
    "\n",
    "    # Preparing the setting and monitoring of the loop\n",
    "    start_time = time()\n",
    "    p_requests = 1\n",
    "        \n",
    "    for v_id in movies_id_list:\n",
    "        if spect:\n",
    "            url_spect = f'https://www.allocine.fr/film/fichefilm-{v_id}/critiques/spectateurs/'    \n",
    "            user_url_list.append(url_spect)\n",
    "        if press:\n",
    "            url_press = f'https://www.allocine.fr/film/fichefilm-{v_id}/critiques/presse/'   \n",
    "            press_url_list.append(url_press)                         \n",
    "        p_requests += 1\n",
    "\n",
    "    # Saving the files\n",
    "    comments_path = 'Movies/Comments/'\n",
    "    print(f'--> Done; {p_requests-1} Movies Comments Page Requests in {timedelta(seconds=time()-start_time)}')\n",
    "    if spect:\n",
    "        r = np.asarray(user_url_list)\n",
    "        np.savetxt(f\"{comments_path}user_comments_urls.csv\", r, delimiter=\",\", fmt='%s')\n",
    "    if press:\n",
    "        r = np.asarray(press_url_list)\n",
    "        np.savetxt(f\"{comments_path}press_comments_urls.csv\", r, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: `getSeriesCommentsUrl(urls)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the comments section url for each series\n",
    "# You can select the spectateurs or presse section, or both\n",
    "def getSeriesCommentsUrl(series_df: pd.DataFrame, spect=False, press=False):\n",
    "    \n",
    "    # Get the list of series_id from the series_df\n",
    "    series_id_list = series_df['id'].tolist()\n",
    "\n",
    "    # Set the list\n",
    "    press_url_list = []\n",
    "    user_url_list = []\n",
    "\n",
    "    # Preparing the setting and monitoring of the loop\n",
    "    start_time = time()\n",
    "    p_requests = 1\n",
    "        \n",
    "    for v_id in series_id_list:\n",
    "        if spect:\n",
    "            url_spect = f'https://www.allocine.fr/series/ficheserie-{v_id}/critiques/'    \n",
    "            user_url_list.append(url_spect)\n",
    "        if press:\n",
    "            url_press = f'https://www.allocine.fr/series/ficheserie-{v_id}/critiques/presse/'   \n",
    "            press_url_list.append(url_press)                         \n",
    "        p_requests += 1\n",
    "\n",
    "    # Saving the files\n",
    "    comments_path = 'Series/Comments/'\n",
    "    print(f'--> Done; {p_requests-1} Series Comments Page Requests in {timedelta(seconds=time()-start_time)}')\n",
    "    if spect:\n",
    "        r = np.asarray(user_url_list)\n",
    "        np.savetxt(f\"{comments_path}user_comments_urls.csv\", r, delimiter=\",\", fmt='%s')\n",
    "    if press:\n",
    "        r = np.asarray(press_url_list)\n",
    "        np.savetxt(f\"{comments_path}press_comments_urls.csv\", r, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main function: `getCommentsUrl(urls)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape the comments section urls from movies and comments previously retrieved urls.\n",
    "# The comments url list is save as a csv file: movies_comments_url.csv (or series_comments_url.csv)\n",
    "def getCommentsUrl(movies_df=None, series_df=None, spect=False, press=False):\n",
    "    \n",
    "    try:\n",
    "        if movies_df is not None:\n",
    "            getMoviesCommentsUrl(movies_df, spect, press)\n",
    "        if series_df is not None:\n",
    "            getSeriesCommentsUrl(series_df, spect, press)\n",
    "    except:\n",
    "        print('Error in getCommentsUrl function!')\n",
    "        traceback.print_exc()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the movies and series dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the movies and series dataframes\n",
    "def loadDataFrames():\n",
    "    movies_df = pd.read_csv('Movies/allocine_movies.csv')\n",
    "    series_df = pd.read_csv('Series/allocine_series.csv')\n",
    "    return movies_df, series_df\n",
    "movies_df, series_df = loadDataFrames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Done; 15 Series Comments Page Requests in 0:00:00\n"
     ]
    }
   ],
   "source": [
    "getCommentsUrl(movies_df=None, series_df=series_df, spect=True, press=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ff1774c64d83fce3825259fa3771bbe70271854497325f5fa1e2c1b92279703"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
